{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7dabcc37",
   "metadata": {},
   "source": [
    "# import all text bbc new doc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e65e0fff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dollar gains on Greenspan speech\n",
      "\n",
      "The dollar has hit its highest level against the euro in almost three months after the Federal Reserve head said the US trade deficit is set to stabilise.\n",
      "\n",
      "And Alan Greenspan highlighted the US government's willingness to curb spending and rising household savings as factors which may help to reduce it. In late trading in New York, the dollar reached $1.2871 against the euro, from $1.2974 on Thursday. Market concerns about the deficit has hit the greenback in recent months. On Friday, Federal Reserve chairman Mr Greenspan's speech in London ahead of the meeting of G7 finance ministers sent the dollar higher after it had earlier tumbled on the back of worse-than-expected US jobs data. \"I think the chairman's taking a much more sanguine view on the current account deficit than he's taken for some time,\" said Robert Sinche, head of currency strategy at Bank of America in New York. \"He's taking a longer-term view, laying out a set of conditions under which the current account deficit can improve this year and next.\"\n",
      "\n",
      "Worries about the deficit concerns about China do, however, remain. China's currency remains pegged to the dollar and the US currency's sharp falls in recent months have therefore made Chinese export prices highly competitive. But calls for a shift in Beijing's policy have fallen on deaf ears, despite recent comments in a major Chinese newspaper that the \"time is ripe\" for a loosening of the peg. The G7 meeting is thought unlikely to produce any meaningful movement in Chinese policy. In the meantime, the US Federal Reserve's decision on 2 February to boost interest rates by a quarter of a point - the sixth such move in as many months - has opened up a differential with European rates. The half-point window, some believe, could be enough to keep US assets looking more attractive, and could help prop up the dollar. The recent falls have partly been the result of big budget deficits, as well as the US's yawning current account gap, both of which need to be funded by the buying of US bonds and assets by foreign firms and governments. The White House will announce its budget on Monday, and many commentators believe the deficit will remain at close to half a trillion dollars.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('News_Articles/business/002.txt') as file:\n",
    "    print(file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a6d9ee8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['business', 'entertainment', 'politics', 'sport', 'tech']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "classes = os.listdir('News_Articles')\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d1e6df58",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = ['News_Articles/' + cl for cl in classes]\n",
    "# file_path = 'News_Articles/' + classes[0]\n",
    "# file_path\n",
    "file_paths\n",
    "path = 'News_Articles'\n",
    "file = f'{path}/{classes[0]}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "680b8154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution complete...\n"
     ]
    }
   ],
   "source": [
    "corpus = {\n",
    "    'business': [] , \n",
    "    'entertainment':[], \n",
    "    'politics': [], \n",
    "    'sport': [],\n",
    "    'tech': []\n",
    "}\n",
    "\n",
    "\n",
    "# helper method to read document from the web\n",
    "def read_document(doc):\n",
    "    with open(doc) as d: \n",
    "        data = d.read()\n",
    "        return data;\n",
    "\n",
    "# print(read_document(f'{path}/{classes[0]}/001.txt'))\n",
    "\n",
    "for cl in classes:\n",
    "    documents = os.listdir(f'{path}/{cl}')\n",
    "    for doc in documents:\n",
    "#         print(doc)\n",
    "        if doc.endswith('.txt'):\n",
    "            data = read_document(f'{path}/{cl}/{doc}')\n",
    "#             appending read document to the dictionary corpus above...\n",
    "            corpus[cl].append(data)\n",
    "    \n",
    "print('Execution complete...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a4116067",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Gallery unveils interactive tree\\n\\nA Christmas tree that can receive text messages has been unveiled at London\\'s Tate Britain art gallery.\\n\\nThe spruce has an antenna which can receive Bluetooth texts sent by visitors to the Tate. The messages will be \"unwrapped\" by sculptor Richard Wentworth, who is responsible for decorating the tree with broken plates and light bulbs. It is the 17th year that the gallery has invited an artist to dress their Christmas tree. Artists who have decorated the Tate tree in previous years include Tracey Emin in 2002.\\n\\nThe plain green Norway spruce is displayed in the gallery\\'s foyer. Its light bulb adornments are dimmed, ordinary domestic ones joined together with string. The plates decorating the branches will be auctioned off for the children\\'s charity ArtWorks. Wentworth worked as an assistant to sculptor Henry Moore in the late 1960s. His reputation as a sculptor grew in the 1980s, while he has been one of the most influential teachers during the last two decades. Wentworth is also known for his photography of mundane, everyday subjects such as a cigarette packet jammed under the wonky leg of a table.\\n'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus['entertainment'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4c491767",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Claxton hunting first major medal\\n\\nBritish hurdler Sarah Claxton is confident she can win her first major medal at next month\\'s European Indoor Championships in Madrid.\\n\\nThe 25-year-old has already smashed the British record over 60m hurdles twice this season, setting a new mark of 7.96 seconds to win the AAAs title. \"I am quite confident,\" said Claxton. \"But I take each race as it comes. \"As long as I keep up my training but not do too much I think there is a chance of a medal.\" Claxton has won the national 60m hurdles title for the past three years but has struggled to translate her domestic success to the international stage. Now, the Scotland-born athlete owns the equal fifth-fastest time in the world this year. And at last week\\'s Birmingham Grand Prix, Claxton left European medal favourite Russian Irina Shevchenko trailing in sixth spot.\\n\\nFor the first time, Claxton has only been preparing for a campaign over the hurdles - which could explain her leap in form. In previous seasons, the 25-year-old also contested the long jump but since moving from Colchester to London she has re-focused her attentions. Claxton will see if her new training regime pays dividends at the European Indoors which take place on 5-6 March.\\n'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus['sport'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "cf0116d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Class : business :  Size : 510\n",
      " Class : entertainment :  Size : 386\n",
      " Class : politics :  Size : 417\n",
      " Class : sport :  Size : 511\n",
      " Class : tech :  Size : 401\n"
     ]
    }
   ],
   "source": [
    "for key , val in corpus.items():\n",
    "    print(f' Class : {key} :  Size : {len(val)}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c40a9189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2225\n",
      "2225\n"
     ]
    }
   ],
   "source": [
    "label = []\n",
    "document = []\n",
    "\n",
    "for key , val in corpus.items():\n",
    "    for v in val:\n",
    "        label.append(key), \n",
    "        document.append(v)\n",
    "    \n",
    "\n",
    "print(len(label))\n",
    "print(len(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c4e4ee32",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>document</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>business</td>\n",
       "      <td>Ad sales boost Time Warner profit\\n\\nQuarterly...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>business</td>\n",
       "      <td>Dollar gains on Greenspan speech\\n\\nThe dollar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>business</td>\n",
       "      <td>Yukos unit buyer faces loan claim\\n\\nThe owner...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>business</td>\n",
       "      <td>High fuel prices hit BA's profits\\n\\nBritish A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>business</td>\n",
       "      <td>Pernod takeover talk lifts Domecq\\n\\nShares in...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                           document\n",
       "0  business  Ad sales boost Time Warner profit\\n\\nQuarterly...\n",
       "1  business  Dollar gains on Greenspan speech\\n\\nThe dollar...\n",
       "2  business  Yukos unit buyer faces loan claim\\n\\nThe owner...\n",
       "3  business  High fuel prices hit BA's profits\\n\\nBritish A...\n",
       "4  business  Pernod takeover talk lifts Domecq\\n\\nShares in..."
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "df = pd.DataFrame(\n",
    "    {'label': label, \n",
    "     'document': document\n",
    "    }\n",
    ")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3617901f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "510    entertainment\n",
       "511    entertainment\n",
       "512    entertainment\n",
       "513    entertainment\n",
       "514    entertainment\n",
       "           ...      \n",
       "891    entertainment\n",
       "892    entertainment\n",
       "893    entertainment\n",
       "894    entertainment\n",
       "895    entertainment\n",
       "Name: label, Length: 386, dtype: object"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'][df.label == 'entertainment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a8fb779d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('bbc_sum_data', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625d29ba",
   "metadata": {},
   "source": [
    "# exploratory data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2848f30b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ea0c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_data  = pd.read_csv('bbc_summary_dataset.csv')\n",
    "r_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fada8b25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>document</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>business</td>\n",
       "      <td>Ad sales boost Time Warner profit\\n\\nQuarterly...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>business</td>\n",
       "      <td>Dollar gains on Greenspan speech\\n\\nThe dollar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>business</td>\n",
       "      <td>Yukos unit buyer faces loan claim\\n\\nThe owner...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>business</td>\n",
       "      <td>High fuel prices hit BA's profits\\n\\nBritish A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>business</td>\n",
       "      <td>Pernod takeover talk lifts Domecq\\n\\nShares in...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                           document\n",
       "0  business  Ad sales boost Time Warner profit\\n\\nQuarterly...\n",
       "1  business  Dollar gains on Greenspan speech\\n\\nThe dollar...\n",
       "2  business  Yukos unit buyer faces loan claim\\n\\nThe owner...\n",
       "3  business  High fuel prices hit BA's profits\\n\\nBritish A...\n",
       "4  business  Pernod takeover talk lifts Domecq\\n\\nShares in..."
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "data  = pd.read_csv('bbc_summary_dataset.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "33624341",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.to_csv('bbc_summary_dataset.csv', index=False)\n",
    "def remove_newline(doc):\n",
    "\n",
    "    doc = ''.join([d.replace('\\n', ' ') for d in doc])\n",
    "    \n",
    "    return doc\n",
    "\n",
    "data['document'] = data['document'].apply(lambda x: remove_newline(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c31b20a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "document = data.document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f32fa0f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Ad sales boost Time Warner profit  Quarterly p...\n",
       "1       Dollar gains on Greenspan speech  The dollar h...\n",
       "2       Yukos unit buyer faces loan claim  The owners ...\n",
       "3       High fuel prices hit BA's profits  British Air...\n",
       "4       Pernod takeover talk lifts Domecq  Shares in U...\n",
       "                              ...                        \n",
       "2220    BT program to beat dialler scams  BT is introd...\n",
       "2221    Spam e-mails tempt net shoppers  Computer user...\n",
       "2222    Be careful how you code  A new European direct...\n",
       "2223    US cyber security chief resigns  The man makin...\n",
       "2224    Losing yourself in online gaming  Online role ...\n",
       "Name: document, Length: 2225, dtype: object"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e99c5f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nltk.tokenize import word_tokenizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "st = stopwords.words('english')\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "cr = ['Ad sales boost Time Warner profit\\n\\nQuarterly profits at US media giant TimeWarner jumped 76% to $1.13bn',\n",
    "     'results following a probe by the US Securities Exchange Commission (SEC), which is close to concluding.\\n\\nTime Warner']\n",
    "\n",
    "def clean_doc(doc):\n",
    "\n",
    "    doc = ''.join([d.replace('\\n', ' ') for d in doc])\n",
    "    token = word_tokenize(doc)\n",
    "    doc = [stemmer.stem(d) for d in token if not d in string.punctuation] \n",
    "    doc = [d for d in doc if not d in st]\n",
    "    \n",
    "    \n",
    "    return doc\n",
    "    \n",
    "# for doc in document:\n",
    "#     print(clean_doc(doc))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54c7856",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['clean_document'] = data['document'].apply(lambda x: clean_doc(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e0ec526b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>document</th>\n",
       "      <th>clean_document</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>business</td>\n",
       "      <td>Ad sales boost Time Warner profit  Quarterly p...</td>\n",
       "      <td>[ad, sale, boost, time, warner, profit, quarte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>business</td>\n",
       "      <td>Dollar gains on Greenspan speech  The dollar h...</td>\n",
       "      <td>[dollar, gain, greenspan, speech, dollar, ha, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>business</td>\n",
       "      <td>Yukos unit buyer faces loan claim  The owners ...</td>\n",
       "      <td>[yuko, unit, buyer, face, loan, claim, owner, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>business</td>\n",
       "      <td>High fuel prices hit BA's profits  British Air...</td>\n",
       "      <td>[high, fuel, price, hit, ba, 's, profit, briti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>business</td>\n",
       "      <td>Pernod takeover talk lifts Domecq  Shares in U...</td>\n",
       "      <td>[pernod, takeov, talk, lift, domecq, share, uk...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                           document  \\\n",
       "0  business  Ad sales boost Time Warner profit  Quarterly p...   \n",
       "1  business  Dollar gains on Greenspan speech  The dollar h...   \n",
       "2  business  Yukos unit buyer faces loan claim  The owners ...   \n",
       "3  business  High fuel prices hit BA's profits  British Air...   \n",
       "4  business  Pernod takeover talk lifts Domecq  Shares in U...   \n",
       "\n",
       "                                      clean_document  \n",
       "0  [ad, sale, boost, time, warner, profit, quarte...  \n",
       "1  [dollar, gain, greenspan, speech, dollar, ha, ...  \n",
       "2  [yuko, unit, buyer, face, loan, claim, owner, ...  \n",
       "3  [high, fuel, price, hit, ba, 's, profit, briti...  \n",
       "4  [pernod, takeov, talk, lift, domecq, share, uk...  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1915878",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting textaugment\n",
      "  Using cached textaugment-1.3.4-py3-none-any.whl (16 kB)\n",
      "Collecting googletrans\n",
      "  Using cached googletrans-3.0.0.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: gensim in c:\\users\\binary\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from textaugment) (4.1.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\binary\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from textaugment) (1.22.3)\n",
      "Requirement already satisfied: nltk in c:\\users\\binary\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from textaugment) (3.7)\n",
      "Collecting textblob\n",
      "  Using cached textblob-0.17.1-py2.py3-none-any.whl (636 kB)\n",
      "Requirement already satisfied: Cython==0.29.23 in c:\\users\\binary\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from gensim->textaugment) (0.29.23)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\binary\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from gensim->textaugment) (5.2.1)\n",
      "Requirement already satisfied: scipy>=0.18.1 in c:\\users\\binary\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from gensim->textaugment) (1.8.0)\n",
      "Collecting httpx==0.13.3\n",
      "  Using cached httpx-0.13.3-py3-none-any.whl (55 kB)\n",
      "Requirement already satisfied: certifi in c:\\users\\binary\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from httpx==0.13.3->googletrans->textaugment) (2021.10.8)\n",
      "INFO: pip is looking at multiple versions of googletrans to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting googletrans\n",
      "  Downloading googletrans-2.4.0.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: requests in c:\\users\\binary\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from googletrans->textaugment) (2.27.1)\n",
      "Requirement already satisfied: joblib in c:\\users\\binary\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from nltk->textaugment) (1.1.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\binary\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from nltk->textaugment) (4.63.1)\n",
      "Requirement already satisfied: click in c:\\users\\binary\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from nltk->textaugment) (8.0.4)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\binary\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from nltk->textaugment) (2022.3.15)\n",
      "Requirement already satisfied: colorama in c:\\users\\binary\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from click->nltk->textaugment) (0.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\binary\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->googletrans->textaugment) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\binary\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->googletrans->textaugment) (2.0.12)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\binary\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->googletrans->textaugment) (1.26.9)\n",
      "Building wheels for collected packages: googletrans\n",
      "  Building wheel for googletrans (setup.py): started\n",
      "  Building wheel for googletrans (setup.py): finished with status 'done'\n",
      "  Created wheel for googletrans: filename=googletrans-2.4.0-py3-none-any.whl size=15789 sha256=aacdf89766bb357b43de168af2fa092967249892cfc0db829ba09ebc5fe60d13\n",
      "  Stored in directory: c:\\users\\binary\\appdata\\local\\pip\\cache\\wheels\\11\\37\\b2\\c72d3f56deb130d693e7f5c425ce583ca2e0498a8397d8384e\n",
      "Successfully built googletrans\n",
      "Installing collected packages: googletrans, textblob, textaugment\n",
      "Successfully installed googletrans-2.4.0 textaugment-1.3.4 textblob-0.17.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\binary\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\binary\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "  WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x0000019A088BC3A0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /packages/fd/f0/a22d41d3846d1f46a4f20086141e0428ccc9c6d644aacbfd30990cf46886/googletrans-2.4.0.tar.gz\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\binary\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\binary\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\binary\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\binary\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\binary\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\binary\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: There was an error checking the latest version of pip.\n"
     ]
    }
   ],
   "source": [
    "# pip install textaugment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "60dd3530",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "\n",
    "model = gensim.models.Word2Vec(\n",
    "    window=10,\n",
    "    min_count=2,\n",
    "    workers = 5 \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "700e0b36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2484664, 2737595)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.build_vocab(data['clean_document'], progress_per = 1000)\n",
    "model.train(data['clean_document'], total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e2c59585",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "# model.save('bbc-summary-w2vec')\n",
    "w2vec = Word2Vec.load(\"bbc-summary-w2vec\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0cd26e62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('play', 0.940715491771698),\n",
       " ('player', 0.8917999267578125),\n",
       " ('rave', 0.8784831166267395),\n",
       " ('joystick', 0.875389039516449),\n",
       " ('chanc', 0.8690231442451477),\n",
       " ('song', 0.8608483672142029),\n",
       " ('grandchildren', 0.8583052754402161),\n",
       " ('win', 0.8515518307685852),\n",
       " ('belt', 0.8265136480331421),\n",
       " ('perform', 0.8204813599586487)]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2vec.wv.most_similar('game')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414c0bd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "430a53b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textaugment import Word2vec\n",
    "t = Word2vec(model='bbc-summary-w2vec', runs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ef7fee04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'quarterly profits at edinburgh burk traill'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.augment('Quarterly profits at US media giant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6524e599",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# sample = []\n",
    "# argsize = 5 \n",
    "# for aug in range(argsize):\n",
    "#   sample.append(t.augment('The man stories are good'))\n",
    "\n",
    "# sample\n",
    "\n",
    "def generate_aurgdata(dataset ,input_col_name, output_col_name , aug_obj):\n",
    "\n",
    "  #              GETTING DATASET META INFO FOR AUG-DATA\n",
    "  # ==================================================================\n",
    "  # getting lenth of each categories in the output coloumns\n",
    "  class_len = []\n",
    "  for classes in dataset[output_col_name].unique():\n",
    "    ln = len(data[data[output_col_name]== classes])\n",
    "    class_len.append(ln)\n",
    "  class_len = np.array(class_len) \n",
    "  # print(class_len)\n",
    "  # getting size of required arg data \n",
    "  missn_data_count = class_len[class_len.argmax()] - class_len\n",
    "  # print(balance_count)\n",
    "  # ================================================================\n",
    "\n",
    "          # GETTING THE AUR DATA READY USING THE MAIN META DATA\n",
    "  # ================================================================\n",
    "  # getting missn count sample set for data source\n",
    "  arg_dataset = {}\n",
    "  class_size = len(missn_data_count)\n",
    "  classes = dataset[output_col_name].unique()\n",
    "  for index in range(class_size):\n",
    "    \n",
    "    samples_set = dataset[dataset[output_col_name] == classes[index]][input_col_name].sample(missn_data_count[index])\n",
    "    print(f'for [{classes[index]}] : we are generating [{len(samples_set)}] arg data ')\n",
    "\n",
    "    # looping through the main sample dataset and generate augdata for it\n",
    "    datum = []\n",
    "    for sample in samples_set:\n",
    "        datum.append(aug_obj.augment(sample))\n",
    "    \n",
    "    # adding it to the dictionary to used in creating data frame leter\n",
    "    arg_dataset[classes[index]] = datum\n",
    "    # print(datum[:2])\n",
    "    # ================================================================\n",
    "\n",
    "  return arg_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "75feef07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for [business] : we are generating [1] arg data \n",
      "for [entertainment] : we are generating [125] arg data \n",
      "for [politics] : we are generating [94] arg data \n",
      "for [sport] : we are generating [0] arg data \n",
      "for [tech] : we are generating [110] arg data \n"
     ]
    }
   ],
   "source": [
    "# testing code snipet\n",
    "import numpy as np\n",
    "arg_datapoint = generate_aurgdata(data, 'document', 'label', t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6a90963f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution completed.........\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dempsey waves damage s debut economy governmen...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sidoli distributor raise piero indecency fines...</td>\n",
       "      <td>entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ronaldo lawsuit korn's shaw quits the wilson w...</td>\n",
       "      <td>entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>poppins musical gets flying race the fortnight...</td>\n",
       "      <td>entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vera roberts takes jason hill vera lane robert...</td>\n",
       "      <td>entertainment</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            document          label\n",
       "0  dempsey waves damage s debut economy governmen...       business\n",
       "1  sidoli distributor raise piero indecency fines...  entertainment\n",
       "2  ronaldo lawsuit korn's shaw quits the wilson w...  entertainment\n",
       "3  poppins musical gets flying race the fortnight...  entertainment\n",
       "4  vera roberts takes jason hill vera lane robert...  entertainment"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "# data_stack = {\n",
    "#     'category': ['tech', 'com'], \n",
    "#     'text': ['this is cool', 'ilove u']\n",
    "# }\n",
    "\n",
    "def get_dataframe():\n",
    "\n",
    "  arg_stack = {\n",
    "      'document':[], \n",
    "      'label':[]\n",
    "  }\n",
    "\n",
    "  for cat, samples in arg_datapoint.items():\n",
    "    for samp in samples: \n",
    "      arg_stack['document'].append(samp)\n",
    "      arg_stack['label'].append(cat)\n",
    "\n",
    "\n",
    "  arg_dataframe = pd.DataFrame(arg_stack)\n",
    "  arg_dataframe.head()\n",
    "  print('Execution completed.........')\n",
    "\n",
    "  return arg_dataframe\n",
    "\n",
    "df = get_dataframe()\n",
    "df.head()\n",
    "# print(len(df[df['category']=='tech']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b281e87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "fbb1d011",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>document</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>business</td>\n",
       "      <td>Ad sales boost Time Warner profit  Quarterly p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>business</td>\n",
       "      <td>Dollar gains on Greenspan speech  The dollar h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>business</td>\n",
       "      <td>Yukos unit buyer faces loan claim  The owners ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>business</td>\n",
       "      <td>High fuel prices hit BA's profits  British Air...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>business</td>\n",
       "      <td>Pernod takeover talk lifts Domecq  Shares in U...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2550</th>\n",
       "      <td>tech</td>\n",
       "      <td>choos ordinari lets hilari fans browse if you ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2551</th>\n",
       "      <td>tech</td>\n",
       "      <td>oversea showcas takes greg mari ga marr the to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2552</th>\n",
       "      <td>tech</td>\n",
       "      <td>hotspot users processor free window calls peop...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2553</th>\n",
       "      <td>tech</td>\n",
       "      <td>apple unveils webster capt mini' apple has unv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2554</th>\n",
       "      <td>tech</td>\n",
       "      <td>bergamasco backs sony 25 technology a still ge...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2555 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         label                                           document\n",
       "0     business  Ad sales boost Time Warner profit  Quarterly p...\n",
       "1     business  Dollar gains on Greenspan speech  The dollar h...\n",
       "2     business  Yukos unit buyer faces loan claim  The owners ...\n",
       "3     business  High fuel prices hit BA's profits  British Air...\n",
       "4     business  Pernod takeover talk lifts Domecq  Shares in U...\n",
       "...        ...                                                ...\n",
       "2550      tech  choos ordinari lets hilari fans browse if you ...\n",
       "2551      tech  oversea showcas takes greg mari ga marr the to...\n",
       "2552      tech  hotspot users processor free window calls peop...\n",
       "2553      tech  apple unveils webster capt mini' apple has unv...\n",
       "2554      tech  bergamasco backs sony 25 technology a still ge...\n",
       "\n",
       "[2555 rows x 2 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# helper method can also be design for this\n",
    "df1 = data[['label', 'document']]\n",
    "df_arg = df\n",
    "super_data = pd.concat([df1, df_arg], ignore_index=True)\n",
    "super_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c91a4e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to csv\n",
    "super_data.to_csv('super_bbcnews_data.csv', index=False)\n",
    "\n",
    "# import pandas as pd \n",
    "# super_data = pd.read_csv('super_bbcnews_data.csv')\n",
    "# super_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "dd61c5b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>document</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>business</td>\n",
       "      <td>Ad sales boost Time Warner profit  Quarterly p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>business</td>\n",
       "      <td>Dollar gains on Greenspan speech  The dollar h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>business</td>\n",
       "      <td>Yukos unit buyer faces loan claim  The owners ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>business</td>\n",
       "      <td>High fuel prices hit BA's profits  British Air...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>business</td>\n",
       "      <td>Pernod takeover talk lifts Domecq  Shares in U...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                           document\n",
       "0  business  Ad sales boost Time Warner profit  Quarterly p...\n",
       "1  business  Dollar gains on Greenspan speech  The dollar h...\n",
       "2  business  Yukos unit buyer faces loan claim  The owners ...\n",
       "3  business  High fuel prices hit BA's profits  British Air...\n",
       "4  business  Pernod takeover talk lifts Domecq  Shares in U..."
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "super_data = pd.read_csv('super_bbcnews_data.csv')\n",
    "super_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a1b51770",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "511"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_size = len(super_data[super_data['label']=='sport'])\n",
    "df_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "01a41bf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "business : 511\n",
      "entertainment : 511\n",
      "politics : 511\n",
      "sport : 511\n",
      "tech : 511\n"
     ]
    }
   ],
   "source": [
    "for l in super_data.label.unique():\n",
    "#     print('label : ' , l)\n",
    "    lb_size = len(super_data[super_data['label']==l])\n",
    "    print(f'{l} : {lb_size}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86af053b",
   "metadata": {},
   "source": [
    "# clean the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9813b24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "super_data['clean_document'] = super_data['document'].apply(lambda x: clean_doc(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "448f43a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>document</th>\n",
       "      <th>clean_document</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2309</th>\n",
       "      <td>entertainment</td>\n",
       "      <td>o'driscol hear cuts nudity from correspond glo...</td>\n",
       "      <td>[o'driscol, hear, cut, nuditi, correspond, glo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1303</th>\n",
       "      <td>politics</td>\n",
       "      <td>Howard hits back at mongrel jibe  Michael Howa...</td>\n",
       "      <td>[howard, hit, back, mongrel, jibe, michael, ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1754</th>\n",
       "      <td>sport</td>\n",
       "      <td>Hingis to make unexpected return  Martina Hing...</td>\n",
       "      <td>[hingi, make, unexpect, return, martina, hingi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1053</th>\n",
       "      <td>politics</td>\n",
       "      <td>Petrol duties frozen, Brown says  Chancellor G...</td>\n",
       "      <td>[petrol, duti, frozen, brown, say, chancellor,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2479</th>\n",
       "      <td>tech</td>\n",
       "      <td>â£80m in the â£200 growing therefor high-speed...</td>\n",
       "      <td>[â£80m, â£200, grow, therefor, high-spe, spywa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              label                                           document  \\\n",
       "2309  entertainment  o'driscol hear cuts nudity from correspond glo...   \n",
       "1303       politics  Howard hits back at mongrel jibe  Michael Howa...   \n",
       "1754          sport  Hingis to make unexpected return  Martina Hing...   \n",
       "1053       politics  Petrol duties frozen, Brown says  Chancellor G...   \n",
       "2479           tech  â£80m in the â£200 growing therefor high-speed...   \n",
       "\n",
       "                                         clean_document  \n",
       "2309  [o'driscol, hear, cut, nuditi, correspond, glo...  \n",
       "1303  [howard, hit, back, mongrel, jibe, michael, ho...  \n",
       "1754  [hingi, make, unexpect, return, martina, hingi...  \n",
       "1053  [petrol, duti, frozen, brown, say, chancellor,...  \n",
       "2479  [â£80m, â£200, grow, therefor, high-spe, spywa...  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "super_data = super_data.sample(df_size)\n",
    "super_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "dea28fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# colum_len\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "st_words = stopwords.words('english')\n",
    "from nltk.stem import PorterStemmer\n",
    "import string\n",
    "ps = PorterStemmer()\n",
    "\n",
    "\n",
    "# DATA PREPARATION\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "lb = LabelEncoder()\n",
    "super_data['label'] = lb.fit_transform(super_data['label'])\n",
    "from sklearn import model_selection\n",
    "# clean_dataset.head()\n",
    "strainx, stestx , strainy , stesty = model_selection.train_test_split(super_data['clean_document'], super_data['label'], test_size=0.2, shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "3e9cf60e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train x : 408\n",
      "test  x : 103\n",
      "train y : 408\n",
      "test x : 103\n"
     ]
    }
   ],
   "source": [
    "print(f'train x : {len(strainx)}' )\n",
    "print(f'test  x : {len(stestx)}' )\n",
    "print(f'train y : {len(strainy)}' )\n",
    "print(f'test x : {len(stesty)}' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "aff743ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10747\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(408, 5000)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn import model_selection\n",
    "\n",
    "sbbc_tokenizer = Tokenizer(num_words=11000, oov_token='<00V>')\n",
    "sbbc_tokenizer.fit_on_texts(strainx)\n",
    "print(len(sbbc_tokenizer.word_index))\n",
    "\n",
    "strainx_sequence = sbbc_tokenizer.texts_to_sequences(strainx)\n",
    "stestx_sequence = sbbc_tokenizer.texts_to_sequences(stestx)\n",
    "\n",
    "# padding the sequences \n",
    "max_val = 5000\n",
    "strain_pad = pad_sequences(strainx_sequence, maxlen=max_val)\n",
    "stest_pad = pad_sequences(stestx_sequence, maxlen=max_val)\n",
    "strain_pad.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "b5a6fe05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, 5000, 100)         1100000   \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 100)               80400     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 5)                 505       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,191,005\n",
      "Trainable params: 1,191,005\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "vocab_size = 11000\n",
    "embedding_dim = 100\n",
    "pad_length =5000\n",
    "\n",
    "en_lstm_model = tf.keras.Sequential([\n",
    "    \n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=pad_length),\n",
    "#   tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, dropout=0.2, recurrent_dropout=0.5)),\n",
    "    tf.keras.layers.LSTM(100, dropout=0.5),\n",
    "    \n",
    "    tf.keras.layers.Dense(100, activation='relu'),\n",
    "    tf.keras.layers.Dense(5, activation='sigmoid')\n",
    "    \n",
    "])\n",
    "\n",
    "\n",
    "en_lstm_model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'] )\n",
    "en_lstm_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "8ee6923b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "13/13 [==============================] - 182s 14s/step - loss: 1.6065 - accuracy: 0.2426 - val_loss: 1.6069 - val_accuracy: 0.2136\n",
      "Epoch 2/8\n",
      "13/13 [==============================] - 220s 17s/step - loss: 1.5830 - accuracy: 0.2598 - val_loss: 1.5943 - val_accuracy: 0.2136\n",
      "Epoch 3/8\n",
      "13/13 [==============================] - 211s 16s/step - loss: 1.5425 - accuracy: 0.3358 - val_loss: 1.5613 - val_accuracy: 0.3786\n",
      "Epoch 4/8\n",
      "13/13 [==============================] - 239s 19s/step - loss: 1.4268 - accuracy: 0.6495 - val_loss: 1.4523 - val_accuracy: 0.3010\n",
      "Epoch 5/8\n",
      "13/13 [==============================] - 254s 19s/step - loss: 1.0993 - accuracy: 0.6103 - val_loss: 1.2452 - val_accuracy: 0.5243\n",
      "Epoch 6/8\n",
      "13/13 [==============================] - 222s 17s/step - loss: 0.7668 - accuracy: 0.8505 - val_loss: 0.9178 - val_accuracy: 0.6408\n",
      "Epoch 7/8\n",
      "13/13 [==============================] - 202s 16s/step - loss: 0.2941 - accuracy: 0.9387 - val_loss: 0.5995 - val_accuracy: 0.7573\n",
      "Epoch 8/8\n",
      "13/13 [==============================] - 203s 16s/step - loss: 0.1406 - accuracy: 0.9902 - val_loss: 0.8176 - val_accuracy: 0.7476\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2033012f520>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_lstm_model.fit(strain_pad, strainy , epochs=8, validation_data=(stest_pad, stesty), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "f5b05a4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 5s 1s/step - loss: 0.8176 - accuracy: 0.7476\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8176298141479492, 0.7475728392601013]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_lstm_model.evaluate(stest_pad, stesty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "9ffb7369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 5s 1s/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.91      0.89        22\n",
      "           1       0.92      0.48      0.63        23\n",
      "           2       0.52      0.78      0.62        18\n",
      "           3       0.95      0.82      0.88        22\n",
      "           4       0.64      0.78      0.70        18\n",
      "\n",
      "    accuracy                           0.75       103\n",
      "   macro avg       0.78      0.75      0.74       103\n",
      "weighted avg       0.79      0.75      0.75       103\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# en_lstm_model.evaluate(stest_pad, stesty)\n",
    "\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "\n",
    "result = en_lstm_model.predict(stest_pad)\n",
    "prediction = [np.argmax(res) for res in result]\n",
    "# prediction\n",
    "classs_report = metrics.classification_report(stesty, prediction)\n",
    "print(classs_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054e8655",
   "metadata": {},
   "source": [
    "# WORD NET "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "87f37c1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>document</th>\n",
       "      <th>clean_document</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>business</td>\n",
       "      <td>Ad sales boost Time Warner profit  Quarterly p...</td>\n",
       "      <td>[ad, sale, boost, time, warner, profit, quarte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>business</td>\n",
       "      <td>Dollar gains on Greenspan speech  The dollar h...</td>\n",
       "      <td>[dollar, gain, greenspan, speech, dollar, ha, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>business</td>\n",
       "      <td>Yukos unit buyer faces loan claim  The owners ...</td>\n",
       "      <td>[yuko, unit, buyer, face, loan, claim, owner, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>business</td>\n",
       "      <td>High fuel prices hit BA's profits  British Air...</td>\n",
       "      <td>[high, fuel, price, hit, ba, 's, profit, briti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>business</td>\n",
       "      <td>Pernod takeover talk lifts Domecq  Shares in U...</td>\n",
       "      <td>[pernod, takeov, talk, lift, domecq, share, uk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2220</th>\n",
       "      <td>tech</td>\n",
       "      <td>BT program to beat dialler scams  BT is introd...</td>\n",
       "      <td>[bt, program, beat, dialler, scam, bt, introdu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2221</th>\n",
       "      <td>tech</td>\n",
       "      <td>Spam e-mails tempt net shoppers  Computer user...</td>\n",
       "      <td>[spam, e-mail, tempt, net, shopper, comput, us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2222</th>\n",
       "      <td>tech</td>\n",
       "      <td>Be careful how you code  A new European direct...</td>\n",
       "      <td>[care, code, new, european, direct, could, put...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2223</th>\n",
       "      <td>tech</td>\n",
       "      <td>US cyber security chief resigns  The man makin...</td>\n",
       "      <td>[us, cyber, secur, chief, resign, man, make, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2224</th>\n",
       "      <td>tech</td>\n",
       "      <td>Losing yourself in online gaming  Online role ...</td>\n",
       "      <td>[lose, onlin, game, onlin, role, play, game, t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2225 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         label                                           document  \\\n",
       "0     business  Ad sales boost Time Warner profit  Quarterly p...   \n",
       "1     business  Dollar gains on Greenspan speech  The dollar h...   \n",
       "2     business  Yukos unit buyer faces loan claim  The owners ...   \n",
       "3     business  High fuel prices hit BA's profits  British Air...   \n",
       "4     business  Pernod takeover talk lifts Domecq  Shares in U...   \n",
       "...        ...                                                ...   \n",
       "2220      tech  BT program to beat dialler scams  BT is introd...   \n",
       "2221      tech  Spam e-mails tempt net shoppers  Computer user...   \n",
       "2222      tech  Be careful how you code  A new European direct...   \n",
       "2223      tech  US cyber security chief resigns  The man makin...   \n",
       "2224      tech  Losing yourself in online gaming  Online role ...   \n",
       "\n",
       "                                         clean_document  \n",
       "0     [ad, sale, boost, time, warner, profit, quarte...  \n",
       "1     [dollar, gain, greenspan, speech, dollar, ha, ...  \n",
       "2     [yuko, unit, buyer, face, loan, claim, owner, ...  \n",
       "3     [high, fuel, price, hit, ba, 's, profit, briti...  \n",
       "4     [pernod, takeov, talk, lift, domecq, share, uk...  \n",
       "...                                                 ...  \n",
       "2220  [bt, program, beat, dialler, scam, bt, introdu...  \n",
       "2221  [spam, e-mail, tempt, net, shopper, comput, us...  \n",
       "2222  [care, code, new, european, direct, could, put...  \n",
       "2223  [us, cyber, secur, chief, resign, man, make, s...  \n",
       "2224  [lose, onlin, game, onlin, role, play, game, t...  \n",
       "\n",
       "[2225 rows x 3 columns]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data.drop('clean_document', inplace=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "a2e8417b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for [business] : we are generating [1] arg data \n",
      "for [entertainment] : we are generating [125] arg data \n",
      "for [politics] : we are generating [94] arg data \n",
      "for [sport] : we are generating [0] arg data \n",
      "for [tech] : we are generating [110] arg data \n",
      "Execution completed.........\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>document</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>business</td>\n",
       "      <td>rich snap half colombia poor fund half of the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>entertainment</td>\n",
       "      <td>portishead back after eight days cult british ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>entertainment</td>\n",
       "      <td>tv show unites angolan kinsfolk angolan phratr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>entertainment</td>\n",
       "      <td>films on war victory at sundance a study of th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>entertainment</td>\n",
       "      <td>bangkok film festival battles on pda of the th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           label                                           document\n",
       "0       business  rich snap half colombia poor fund half of the ...\n",
       "1  entertainment  portishead back after eight days cult british ...\n",
       "2  entertainment  tv show unites angolan kinsfolk angolan phratr...\n",
       "3  entertainment  films on war victory at sundance a study of th...\n",
       "4  entertainment  bangkok film festival battles on pda of the th..."
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textaugment import Wordnet\n",
    "\n",
    "wdn_aug = Wordnet(v=False ,n=True, p=0.5)\n",
    "# wdn_aug.augment('In the afternoon, John is going to town')\n",
    "# wdn_aug\n",
    "\n",
    "# def generate_aurgdata(dataset ,input_col_name, output_col_name , aug_obj):\n",
    "import numpy as np\n",
    "wdn_aud_data = generate_aurgdata(data, 'document', 'label', wdn_aug)\n",
    "\n",
    "import pandas as pd \n",
    "# data_stack = {\n",
    "#     'category': ['tech', 'com'], \n",
    "#     'text': ['this is cool', 'ilove u']\n",
    "# }\n",
    "\n",
    "def get_dataframe():\n",
    "\n",
    "  arg_stack = {\n",
    "      'label':[], \n",
    "      'document':[]\n",
    "  }\n",
    "\n",
    "  for cat, samples in wdn_aud_data.items():\n",
    "    for samp in samples: \n",
    "      arg_stack['document'].append(samp)\n",
    "      arg_stack['label'].append(cat)\n",
    "\n",
    "\n",
    "  arg_dataframe = pd.DataFrame(arg_stack)\n",
    "  arg_dataframe.head()\n",
    "  print('Execution completed.........')\n",
    "\n",
    "  return arg_dataframe\n",
    "\n",
    "df = get_dataframe()\n",
    "df.head()\n",
    "# print(len(df[df['category']=='tech']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "a99f9b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# helper method can also be design for this\n",
    "df1 = data[['label', 'document']]\n",
    "df_arg = df\n",
    "super_data = pd.concat([df1, df_arg], ignore_index=True)\n",
    "super_data.head(2)\n",
    "\n",
    "# write to csv\n",
    "# super_data.to_csv('wdnet_super_bbcnews_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f88e3f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>document</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>business</td>\n",
       "      <td>Ad sales boost Time Warner profit  Quarterly p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>business</td>\n",
       "      <td>Dollar gains on Greenspan speech  The dollar h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>business</td>\n",
       "      <td>Yukos unit buyer faces loan claim  The owners ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>business</td>\n",
       "      <td>High fuel prices hit BA's profits  British Air...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>business</td>\n",
       "      <td>Pernod takeover talk lifts Domecq  Shares in U...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                           document\n",
       "0  business  Ad sales boost Time Warner profit  Quarterly p...\n",
       "1  business  Dollar gains on Greenspan speech  The dollar h...\n",
       "2  business  Yukos unit buyer faces loan claim  The owners ...\n",
       "3  business  High fuel prices hit BA's profits  British Air...\n",
       "4  business  Pernod takeover talk lifts Domecq  Shares in U..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import pandas as pd \n",
    "wdnet_super_data = pd.read_csv('wdnet_super_bbcnews_data.csv')\n",
    "wdnet_super_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15884ab1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>document</th>\n",
       "      <th>clean_document</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>business</td>\n",
       "      <td>Ad sales boost Time Warner profit  Quarterly p...</td>\n",
       "      <td>[ad, sale, boost, time, warner, profit, quarte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>business</td>\n",
       "      <td>Dollar gains on Greenspan speech  The dollar h...</td>\n",
       "      <td>[dollar, gain, greenspan, speech, dollar, ha, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>business</td>\n",
       "      <td>Yukos unit buyer faces loan claim  The owners ...</td>\n",
       "      <td>[yuko, unit, buyer, face, loan, claim, owner, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>business</td>\n",
       "      <td>High fuel prices hit BA's profits  British Air...</td>\n",
       "      <td>[high, fuel, price, hit, ba, 's, profit, briti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>business</td>\n",
       "      <td>Pernod takeover talk lifts Domecq  Shares in U...</td>\n",
       "      <td>[pernod, takeov, talk, lift, domecq, share, uk...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                           document  \\\n",
       "0  business  Ad sales boost Time Warner profit  Quarterly p...   \n",
       "1  business  Dollar gains on Greenspan speech  The dollar h...   \n",
       "2  business  Yukos unit buyer faces loan claim  The owners ...   \n",
       "3  business  High fuel prices hit BA's profits  British Air...   \n",
       "4  business  Pernod takeover talk lifts Domecq  Shares in U...   \n",
       "\n",
       "                                      clean_document  \n",
       "0  [ad, sale, boost, time, warner, profit, quarte...  \n",
       "1  [dollar, gain, greenspan, speech, dollar, ha, ...  \n",
       "2  [yuko, unit, buyer, face, loan, claim, owner, ...  \n",
       "3  [high, fuel, price, hit, ba, 's, profit, briti...  \n",
       "4  [pernod, takeov, talk, lift, domecq, share, uk...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "colum = wdnet_super_data.label.unique()\n",
    "colum_len = [] \n",
    "for index in range(len(colum)):\n",
    "  lenght = len(wdnet_super_data[wdnet_super_data['label']== colum[index]])\n",
    "  colum_len.append(lenght)\n",
    "\n",
    "colum_len\n",
    "\n",
    "wdnet_super_data['clean_document'] = wdnet_super_data[\"document\"].apply(lambda x: clean_doc(x))\n",
    "\n",
    "wdnet_super_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0315199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24356\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2044, 5000)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "lb = LabelEncoder()\n",
    "wdnet_super_data['label'] = lb.fit_transform(wdnet_super_data['label'])\n",
    "from sklearn import model_selection\n",
    "# clean_dataset.head()\n",
    "strainx, stestx , strainy , stesty = model_selection.train_test_split(wdnet_super_data['clean_document'], wdnet_super_data['label'], test_size=0.2, shuffle=False)\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn import model_selection\n",
    "\n",
    "sbbc_tokenizer = Tokenizer(num_words=25000, oov_token='<00V>')\n",
    "sbbc_tokenizer.fit_on_texts(strainx)\n",
    "print(len(sbbc_tokenizer.word_index))\n",
    "\n",
    "strainx_sequence = sbbc_tokenizer.texts_to_sequences(strainx)\n",
    "stestx_sequence = sbbc_tokenizer.texts_to_sequences(stestx)\n",
    "\n",
    "# padding the sequences \n",
    "max_val = 5000\n",
    "strain_pad = pad_sequences(strainx_sequence, maxlen=max_val)\n",
    "stest_pad = pad_sequences(stestx_sequence, maxlen=max_val)\n",
    "strain_pad.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6bfacecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 5000, 100)         2500000   \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 100)               80400     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 5)                 505       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,591,005\n",
      "Trainable params: 2,591,005\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "vocab_size = 25000\n",
    "embedding_dim = 100\n",
    "pad_length =5000\n",
    "\n",
    "wd_lstm_model = tf.keras.Sequential([\n",
    "    \n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=pad_length),\n",
    "#   tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, dropout=0.2, recurrent_dropout=0.5)),\n",
    "    tf.keras.layers.LSTM(100, dropout=0.5),\n",
    "    \n",
    "    tf.keras.layers.Dense(100, activation='relu'),\n",
    "    tf.keras.layers.Dense(5, activation='sigmoid')\n",
    "    \n",
    "])\n",
    "\n",
    "\n",
    "wd_lstm_model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'] )\n",
    "wd_lstm_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "181ea2ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "64/64 [==============================] - 605s 9s/step - loss: 1.5354 - accuracy: 0.3322 - val_loss: 1.5093 - val_accuracy: 0.2661\n",
      "Epoch 2/8\n",
      "64/64 [==============================] - 764s 12s/step - loss: 0.7794 - accuracy: 0.7065 - val_loss: 0.9584 - val_accuracy: 0.3992\n",
      "Epoch 3/8\n",
      "64/64 [==============================] - 772s 12s/step - loss: 0.2954 - accuracy: 0.8885 - val_loss: 0.5808 - val_accuracy: 0.8356\n",
      "Epoch 4/8\n",
      "64/64 [==============================] - 707s 11s/step - loss: 0.1143 - accuracy: 0.9662 - val_loss: 0.3956 - val_accuracy: 0.8611\n",
      "Epoch 5/8\n",
      "64/64 [==============================] - 690s 11s/step - loss: 0.0771 - accuracy: 0.9814 - val_loss: 0.1798 - val_accuracy: 0.9452\n",
      "Epoch 6/8\n",
      "64/64 [==============================] - 696s 11s/step - loss: 0.0198 - accuracy: 0.9936 - val_loss: 0.1779 - val_accuracy: 0.9511\n",
      "Epoch 7/8\n",
      "64/64 [==============================] - 725s 11s/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.1743 - val_accuracy: 0.9452\n",
      "Epoch 8/8\n",
      "64/64 [==============================] - 682s 11s/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.1881 - val_accuracy: 0.9511\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x203d80edaf0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wd_lstm_model.fit(strain_pad, strainy , epochs=8, validation_data=(stest_pad, stesty), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "883c450b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 21s 1s/step - loss: 0.1881 - accuracy: 0.9511\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.1881158947944641, 0.951076328754425]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wd_lstm_model.evaluate(stest_pad, stesty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "17591085",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 21s 1s/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      1.00      0.17         1\n",
      "           1       0.94      1.00      0.97       125\n",
      "           2       0.93      1.00      0.96        94\n",
      "           4       1.00      0.91      0.96       291\n",
      "\n",
      "    accuracy                           0.95       511\n",
      "   macro avg       0.74      0.98      0.76       511\n",
      "weighted avg       0.97      0.95      0.96       511\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "\n",
    "result = wd_lstm_model.predict(stest_pad)\n",
    "prediction = [np.argmax(res) for res in result]\n",
    "# prediction\n",
    "classs_report = metrics.classification_report(stesty, prediction)\n",
    "print(classs_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b4f0b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
