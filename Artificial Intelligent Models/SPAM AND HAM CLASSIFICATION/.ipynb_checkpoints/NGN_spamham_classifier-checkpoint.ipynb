{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORTING NGN DATASET 1 USING PANDAS..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>*IMPORTANT* NetBank Security requires you to a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Win a ÃÂ¥ÃÂ£1000 cash prize or a prize worth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>UR GOING 2 BAHAMAS! CallFREEFONE 08081560665 a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Sequel to the receipt of your Resume, the Boar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>WIN a ÃÂ¥ÃÂ£200 Shopping spree every WEEK St...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                            message\n",
       "0      0  *IMPORTANT* NetBank Security requires you to a...\n",
       "1      0  Win a ÃÂ¥ÃÂ£1000 cash prize or a prize worth...\n",
       "2      0  UR GOING 2 BAHAMAS! CallFREEFONE 08081560665 a...\n",
       "3      0  Sequel to the receipt of your Resume, the Boar...\n",
       "4      0  WIN a ÃÂ¥ÃÂ£200 Shopping spree every WEEK St..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data_ngn = pd.read_csv('sms_spam_ham_ng.csv')\n",
    "data_ngn.head()\n",
    "#data_ngn.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLEANING NGN DATASET.. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[importnetbanksecurrequirauthorisdevicimmediac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[£1000]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>[£2000]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>[sequelreceiptresumboardlsresourcrequestpresen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>[£200]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                            message\n",
       "0      0  [importnetbanksecurrequirauthorisdevicimmediac...\n",
       "1      0                                            [£1000]\n",
       "2      0                                            [£2000]\n",
       "3      0  [sequelreceiptresumboardlsresourcrequestpresen...\n",
       "4      0                                             [£200]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data_ngn.to_string()\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "from nltk.stem import PorterStemmer \n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# print(string.punctuation)\n",
    "stop_word = stopwords.words('english')\n",
    "\n",
    "def preprocessing(text):\n",
    "    st = PorterStemmer()\n",
    "    clean_puct = ''.join([p for p in text if not p in string.punctuation])    \n",
    "    # tokinization of each row (message)\n",
    "    token = word_tokenize(clean_puct)\n",
    "    \n",
    "    # to remove somethin of this nature in dataset %&*^*^%£500\n",
    "    #   and stemming individuals word using porter stemmer \n",
    "    clean_tok = []\n",
    "    for tok in token:\n",
    "        found = re.search('([£][0-9]+)', tok)\n",
    "        if found:\n",
    "            clean_tok.append(found.group(0))\n",
    "        else:\n",
    "            clean_tok.append(st.stem(tok))\n",
    "    token = clean_tok\n",
    "\n",
    "\n",
    "    punc = [t for t in token if not t in string.punctuation]\n",
    "#     clean_words = [t for t in punc if not t in stop_word ]\n",
    "    return clean_words\n",
    "\n",
    "#     end of preprocessing method\n",
    "\n",
    "    \n",
    "data_ngn['message'] = data_ngn['message'].apply(lambda x:preprocessing(x))\n",
    "data_ngn.head()\n",
    "# data_ngn['clean_message'].to_string()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA EXPLORATION ON NGN DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty message =  0\n",
      "No of messages  1008\n",
      "Columns  2\n"
     ]
    }
   ],
   "source": [
    "# checking for empty row\n",
    "print('Empty message = ' , data_ngn['message'].isnull().sum())\n",
    "print('No of messages ' , len(data_ngn))\n",
    "print('Columns ', len(data_ngn.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# converting 0 = spam "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>spam</td>\n",
       "      <td>[import, netbank, secur, requir, authoris, dev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>spam</td>\n",
       "      <td>[win, £1000, cash, prize, prize, worth, £5000]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>spam</td>\n",
       "      <td>[UR, go, 2, bahama, callfreefon, 08081560665, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>spam</td>\n",
       "      <td>[sequel, receipt, resum, board, lsresourc, req...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>spam</td>\n",
       "      <td>[win, £200, shop, spree, everi, week, start, 2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message\n",
       "0  spam  [import, netbank, secur, requir, authoris, dev...\n",
       "1  spam     [win, £1000, cash, prize, prize, worth, £5000]\n",
       "2  spam  [UR, go, 2, bahama, callfreefon, 08081560665, ...\n",
       "3  spam  [sequel, receipt, resum, board, lsresourc, req...\n",
       "4  spam  [win, £200, shop, spree, everi, week, start, 2..."
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_ngn['label'] = ['spam' for label in data_ngn['label'] ]\n",
    "data_ngn.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPLITTING NGN DATASE TO TRAIN AND TEST "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORT DATASET SMS_spam Kaggle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "pd.set_option.display_max_row = 100\n",
    "dataset  = pd.read_csv('SMSSPamCollection', sep='\\t' , header=None)\n",
    "dataset.columns = ['label', 'message']\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA EXPLORATION ON KAGGLE DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ham lenght:4825 spam lenght:747\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as pyt\n",
    "import numpy as np\n",
    "\n",
    "# getting size of ham and spam in the message .... \n",
    "ham_size = len([ham for ham in dataset['label'] if ham =='ham'])\n",
    "spam_size = len([spam for spam in dataset['label'] if spam == 'spam'])\n",
    "print(f'ham lenght:{ham_size} spam lenght:{spam_size}')\n",
    "\n",
    "#dataset visualization\n",
    "X = np.array(['HAM', 'SPAM'])\n",
    "y = np.array([ham_size, spam_size])\n",
    "pyt.bar(X,y)\n",
    "pyt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "goe\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>ham</td>\n",
       "      <td>[Go, jurong, point, crazi, avail, bugi, n, gre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>ham</td>\n",
       "      <td>[Ok, lar, joke, wif, u, oni]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>spam</td>\n",
       "      <td>[free, entri, 2, wkli, comp, win, FA, cup, fin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>ham</td>\n",
       "      <td>[U, dun, say, earli, hor, U, c, alreadi, say]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>ham</td>\n",
       "      <td>[nah, I, dont, think, goe, usf, live, around, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message\n",
       "0   ham  [Go, jurong, point, crazi, avail, bugi, n, gre...\n",
       "1   ham                       [Ok, lar, joke, wif, u, oni]\n",
       "2  spam  [free, entri, 2, wkli, comp, win, FA, cup, fin...\n",
       "3   ham      [U, dun, say, earli, hor, U, c, alreadi, say]\n",
       "4   ham  [nah, I, dont, think, goe, usf, live, around, ..."
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import pandas as pd\n",
    "\n",
    "ps = PorterStemmer()\n",
    "print(ps.stem('goes'))\n",
    "stopword = stopwords.words('english')\n",
    "# print(st)\n",
    "\n",
    "def clean_dataset(data):\n",
    "    sentence = ''.join([t for t in data if not t in string.punctuation])\n",
    "    token = word_tokenize(sentence)\n",
    "    stem_token = [ps.stem(word) for word in token if word not in stopword]\n",
    "    return stem_token\n",
    "\n",
    "dataset['message'] = dataset['message'].apply(lambda a: clean_dataset(a))\n",
    "# dataset['msg_clean'] = [message for message in dataset['message']]\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combined NGN and KAGGLE dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>spam</td>\n",
       "      <td>[import, netbank, secur, requir, authoris, dev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>spam</td>\n",
       "      <td>[win, £1000, cash, prize, prize, worth, £5000]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>spam</td>\n",
       "      <td>[UR, go, 2, bahama, callfreefon, 08081560665, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>spam</td>\n",
       "      <td>[sequel, receipt, resum, board, lsresourc, req...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>spam</td>\n",
       "      <td>[win, £200, shop, spree, everi, week, start, 2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message\n",
       "0  spam  [import, netbank, secur, requir, authoris, dev...\n",
       "1  spam     [win, £1000, cash, prize, prize, worth, £5000]\n",
       "2  spam  [UR, go, 2, bahama, callfreefon, 08081560665, ...\n",
       "3  spam  [sequel, receipt, resum, board, lsresourc, req...\n",
       "4  spam  [win, £200, shop, spree, everi, week, start, 2..."
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_data = data_ngn.append(dataset, ignore_index=True)\n",
    "master_data.head()\n",
    "# master.tail()\n",
    "# print(ngn_kaggle_dataset.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# exploring the merge dataset kaggle and ngn data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ham lenght:4825 spam lenght:1755\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as py\n",
    "import numpy as np \n",
    "\n",
    "ham_size = len([ham for ham in master_data['label'] if ham =='ham'])\n",
    "spam_size = len([spam for spam in master_data['label'] if spam == 'spam'])\n",
    "print(f'ham lenght:{ham_size} spam lenght:{spam_size}')\n",
    "\n",
    "X = np.array(['HAM' , 'SPAM'])\n",
    "y  = np.array([ham_size , spam_size])\n",
    "py.bar(X,y)\n",
    "py.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#    # splitting kaggle data set into training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X lenght 4179\n",
      "x text len  1393\n",
      "y train lenght 4179\n",
      "y test len 1393\n",
      "data spliting completed\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(dataset['message'], dataset['label'], test_size=0.25)\n",
    "print('X lenght' , len(X_train))\n",
    "print('x text len ', len(X_test))\n",
    "print('y train lenght', len(y_train))\n",
    "print('y test len', len(y_test))\n",
    "print('data spliting completed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# splitting master dataset into testing and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklear import model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X lenght 4935\n",
      "x text len  1645\n",
      "y train lenght 4935\n",
      "y test len 1645\n",
      "4615            [that, mean, got, A, epi, she, fine, she]\n",
      "5141    [Hi, babi, ive, got, back, work, want, see, u,...\n",
      "6144    [there, nice, pub, near, franki, n, benni, nea...\n",
      "794     [base, CV, review, shortlist, interview, dg, d...\n",
      "4221                          [We, got, divorc, lol, she]\n",
      "4635         [yeah, right, ill, bring, tape, measur, fri]\n",
      "2382    [bear, pic, nick, tom, pete, dick, In, fact, t...\n",
      "5835                                   [haha, I, thinkin]\n",
      "1400            [hey, sat, go, intro, pilat, Or, kickbox]\n",
      "2910                            [sorri, ill, call, later]\n",
      "Name: message, dtype: object\n",
      "master data spliting completed................\n"
     ]
    }
   ],
   "source": [
    "X_master_train, X_master_test, y_master_train, y_master_test = model_selection.train_test_split(master_data['message'], master_data['label'])\n",
    "print('X lenght' , len(X_master_train))\n",
    "print('x text len ', len(X_master_test))\n",
    "print('y train lenght', len(y_master_train))\n",
    "print('y test len', len(y_master_test))\n",
    "print(X_master_train[:10])\n",
    "print('master data spliting completed................')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VECTORIZING MASTER DATASET USING COUNTVECTORIZER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_master_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-a0e64f1256fd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# learn vocabulary and train\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mX_train_master_cv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_master_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# vectorize testing X\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_master_train' is not defined"
     ]
    }
   ],
   "source": [
    "cv = CountVectorizer(max_features=5000)\n",
    "\n",
    "# learn vocabulary and train \n",
    "X_train_master_cv = cv.fit_transform(X_master_train)\n",
    "\n",
    "# vectorize testing X\n",
    "X_test_master_cv = cv.transform(X_master_test)\n",
    "\n",
    "print()\n",
    "print('vectorizing complete.... ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
